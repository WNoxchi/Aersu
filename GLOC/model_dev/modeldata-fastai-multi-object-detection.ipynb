{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Object Detection - Model Data Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WNixalo - 5/5/2018\n",
    "\n",
    "---\n",
    "\n",
    "This notebook's purpose it to build intuition and practice implementing the fastai workflow for multi-object detection: specifically how to load data w/ a `ModelData` object.\n",
    "\n",
    "**References**: [codealong-pascal-multi](https://github.com/WNoxchi/Aersu/blob/master/GLOC/model_dev/codealong-fastai-dl2-pascal-multi.ipynb) | [fastai pascal-multi](https://github.com/fastai/fastai/blob/master/courses/dl2/pascal-multi.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "\n",
    "sys.path.insert(1, os.path.join('../'))\n",
    "from utils import common\n",
    "from utils import temp_utils\n",
    "from utils.subfolder_val_idxs import set_val_idxs\n",
    "\n",
    "from matplotlib import patches, patheffects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "PATH = Path('../data')\n",
    "PATH_TRAIN     = PATH/'train'\n",
    "PATH_TRAIN_BBX = PATH/'interstage_train'\n",
    "PATH_CSV     = PATH/'labels.csv'\n",
    "PATH_CSV_BBX = PATH/'interstage_labels.csv'\n",
    "CPU_PATH_CSV     = PATH/'cpu_labels.csv'\n",
    "CPU_PATH_CSV_BBX = PATH/'cpu_interstage_labels.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Multi Class from JSON $\\rightarrow$ CSV\n",
    "\n",
    "How do you create a ModelData object for multi-class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'segmentation': [[155, 96, 155, 270, 351, 270, 351, 96]], 'area': 34104, 'iscrowd': 0, 'image_id': 12, 'bbox': [155, 96, 196, 174], 'category_id': 7, 'id': 1, 'ignore': 0}\n",
      "{'segmentation': [[184, 61, 184, 199, 279, 199, 279, 61]], 'area': 13110, 'iscrowd': 0, 'image_id': 17, 'bbox': [184, 61, 95, 138], 'category_id': 15, 'id': 2, 'ignore': 0}\n"
     ]
    }
   ],
   "source": [
    "for i,o in enumerate(trn_j['annotations']):\n",
    "    print(o)\n",
    "    if i == 1: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = Path('../pascal_train2007.json')\n",
    "trn_j = json.load(path.open())\n",
    "\n",
    "def get_trn_anno():\n",
    "    trn_anno = collections.defaultdict(lambda:[])\n",
    "    for o in trn_j['annotations']:\n",
    "#         if not o['ignore']:\n",
    "        if True:\n",
    "            bb = o['bbox']\n",
    "            bb = np.array([bb[1], bb[0], bb[3]+bb[1]-1, bb[2]+bb[0]-1])\n",
    "            trn_anno[o['image_id']].append((bb, o['category_id']))\n",
    "    return trn_anno\n",
    "\n",
    "trn_anno = get_trn_anno()\n",
    "\n",
    "cats = dict((o['id'], o['name']) for o in trn_j['categories'])\n",
    "\n",
    "trn_fns = dict(([o['id'], o['file_name']]) for o in trn_j['images'])\n",
    "\n",
    "trn_ids = [o['id'] for o in trn_j['images']]\n",
    "\n",
    "mc  = [set([cats[p[1]] for p in trn_anno[o]]) for o in trn_ids]\n",
    "mcs = [' '.join(str(p) for p in o) for o in mc]\n",
    "\n",
    "df = pd.DataFrame({'fn':[trn_fns[o] for o in trn_ids], 'class':mcs}, columns=['fn','class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'aeroplane',\n",
       " 2: 'bicycle',\n",
       " 3: 'bird',\n",
       " 4: 'boat',\n",
       " 5: 'bottle',\n",
       " 6: 'bus',\n",
       " 7: 'car',\n",
       " 8: 'cat',\n",
       " 9: 'chair',\n",
       " 10: 'cow',\n",
       " 11: 'diningtable',\n",
       " 12: 'dog',\n",
       " 13: 'horse',\n",
       " 14: 'motorbike',\n",
       " 15: 'person',\n",
       " 16: 'pottedplant',\n",
       " 17: 'sheep',\n",
       " 18: 'sofa',\n",
       " 19: 'train',\n",
       " 20: 'tvmonitor'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, '000012.jpg')\n",
      "(17, '000017.jpg')\n",
      "(23, '000023.jpg')\n",
      "(26, '000026.jpg')\n",
      "(32, '000032.jpg')\n",
      "(33, '000033.jpg')\n",
      "(34, '000034.jpg')\n",
      "(35, '000035.jpg')\n",
      "(36, '000036.jpg')\n",
      "(42, '000042.jpg')\n"
     ]
    }
   ],
   "source": [
    "for i,item in enumerate(trn_fns.items()):\n",
    "    print(item)\n",
    "    if i == 9: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 17, 23, 26, 32, 33, 34, 35, 36, 42]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'car'},\n",
       " {'horse', 'person'},\n",
       " {'bicycle', 'person'},\n",
       " {'car'},\n",
       " {'aeroplane', 'person'},\n",
       " {'aeroplane'},\n",
       " {'train'},\n",
       " {'diningtable', 'person'},\n",
       " {'dog'},\n",
       " {'train'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['car',\n",
       " 'person horse',\n",
       " 'person bicycle',\n",
       " 'car',\n",
       " 'aeroplane person',\n",
       " 'aeroplane',\n",
       " 'train',\n",
       " 'diningtable person',\n",
       " 'dog',\n",
       " 'train']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fn</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000012.jpg</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000017.jpg</td>\n",
       "      <td>person horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000023.jpg</td>\n",
       "      <td>person bicycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000026.jpg</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000032.jpg</td>\n",
       "      <td>aeroplane person</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           fn             class\n",
       "0  000012.jpg               car\n",
       "1  000017.jpg      person horse\n",
       "2  000023.jpg    person bicycle\n",
       "3  000026.jpg               car\n",
       "4  000032.jpg  aeroplane person"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "MC_CSV = path/'tmp/mc.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Object\n",
    "\n",
    "How do you create a ModelData object for multi-object detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc  = [[cats[p[1]] for p in trn_anno[o]] for o in trn_ids]\n",
    "id2cat = list(cats.values())\n",
    "cat2id = {v:k for k,v in enumerate(id2cat)}\n",
    "mcs = np.array([np.array([cat2id[p] for p in o]) for o in mc])\n",
    "\n",
    "mbb  = [np.concatenate([p[0] for p in trn_anno[o]]) for o in trn_ids]\n",
    "mbbs = [' '.join(str(p) for p in o) for o in mbb]\n",
    "\n",
    "df_mbb = pd.DataFrame({'fn':[trn_fns[o] for o in trn_ids], 'bbox':mbbs}, columns=['fn','bbox'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because it's multi *Object* not multi *Class* the number of occurrences of a class in an image is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['car'],\n",
       " ['person', 'horse'],\n",
       " ['bicycle', 'bicycle', 'bicycle', 'person', 'person', 'person'],\n",
       " ['car'],\n",
       " ['aeroplane', 'aeroplane', 'person', 'person'],\n",
       " ['aeroplane', 'aeroplane', 'aeroplane'],\n",
       " ['train', 'train'],\n",
       " ['person', 'person', 'person', 'diningtable'],\n",
       " ['dog'],\n",
       " ['train', 'train']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(id2cat): <class 'list'>; type(cat2id): <class 'dict'>\n",
      "aeroplane          aeroplane : 0\n",
      "bicycle              bicycle : 1\n",
      "bird                    bird : 2\n",
      "boat                    boat : 3\n",
      "bottle                bottle : 4\n",
      "bus                      bus : 5\n",
      "car                      car : 6\n",
      "cat                      cat : 7\n",
      "chair                  chair : 8\n",
      "cow                      cow : 9\n",
      "diningtable      diningtable : 10\n",
      "dog                      dog : 11\n",
      "horse                  horse : 12\n",
      "motorbike          motorbike : 13\n",
      "person                person : 14\n",
      "pottedplant      pottedplant : 15\n",
      "sheep                  sheep : 16\n",
      "sofa                    sofa : 17\n",
      "train                  train : 18\n",
      "tvmonitor          tvmonitor : 19\n"
     ]
    }
   ],
   "source": [
    "print(f'type(id2cat): {type(id2cat)}; type(cat2id): {type(cat2id)}')\n",
    "for ic,ci in zip(id2cat, cat2id.items()):\n",
    "    print(f'{ic:<15}{ci[0]+\" :\":>15} {ci[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([6]), array([14, 12]), array([ 1,  1,  1, 14, 14, 14]), array([6]), array([ 0,  0, 14, 14]),\n",
       "       array([0, 0, 0]), array([18, 18]), array([14, 14, 14, 10]), array([11]), array([18, 18])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's how it's done. `mcs` (multiple classes) contains arrays of class ids. `mbb` (multiple bounding boxes) is the same thing but for coordinates (`mbbs` just changes the format to CSV-compatible strings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 96, 155, 269, 350]),\n",
       " array([ 61, 184, 198, 278,  77,  89, 335, 402]),\n",
       " array([229,   8, 499, 244, 219, 229, 499, 333, 177,   1, 499,  89,   0,   1, 368, 116,   1,   2, 461, 242,\n",
       "          0, 224, 485, 333]),\n",
       " array([124,  89, 211, 336]),\n",
       " array([ 77, 103, 182, 374,  87, 132, 122, 196, 179, 194, 228, 212, 188,  25, 237,  43]),\n",
       " array([106,   8, 262, 498, 199, 420, 225, 481, 187, 324, 222, 410]),\n",
       " array([166, 115, 399, 359, 152, 140, 228, 332]),\n",
       " array([ 95,   0, 360, 190,  97, 217, 317, 464, 194, 467, 316, 499, 303,   2, 374, 499]),\n",
       " array([ 78,  26, 343, 318]),\n",
       " array([ 31, 262, 294, 499,  35,   0, 298, 234])]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbb[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['96 155 269 350',\n",
       " '61 184 198 278 77 89 335 402',\n",
       " '229 8 499 244 219 229 499 333 177 1 499 89 0 1 368 116 1 2 461 242 0 224 485 333',\n",
       " '124 89 211 336',\n",
       " '77 103 182 374 87 132 122 196 179 194 228 212 188 25 237 43',\n",
       " '106 8 262 498 199 420 225 481 187 324 222 410',\n",
       " '166 115 399 359 152 140 228 332',\n",
       " '95 0 360 190 97 217 317 464 194 467 316 499 303 2 374 499',\n",
       " '78 26 343 318',\n",
       " '31 262 294 499 35 0 298 234']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbbs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moment of truth: what does the fastai DataLoader CSV look like for multiple bounding boxes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fn</th>\n",
       "      <th>bbox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000012.jpg</td>\n",
       "      <td>96 155 269 350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000017.jpg</td>\n",
       "      <td>61 184 198 278 77 89 335 402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000023.jpg</td>\n",
       "      <td>229 8 499 244 219 229 499 333 177 1 499 89 0 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000026.jpg</td>\n",
       "      <td>124 89 211 336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000032.jpg</td>\n",
       "      <td>77 103 182 374 87 132 122 196 179 194 228 212 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           fn                                               bbox\n",
       "0  000012.jpg                                     96 155 269 350\n",
       "1  000017.jpg                       61 184 198 278 77 89 335 402\n",
       "2  000023.jpg  229 8 499 244 219 229 499 333 177 1 499 89 0 1...\n",
       "3  000026.jpg                                     124 89 211 336\n",
       "4  000032.jpg  77 103 182 374 87 132 122 196 179 194 228 212 ..."
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mbb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting It Together: Multi-Class CSV + Multi-BoundingBox CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the Bounding Box and Class data have to be merged together so the fastai ModelData object can have access to them. This is done by writing a class to concatenate the two datasets (`mbbs` and `mcs`).\n",
    "\n",
    "A ModelData object is created by loading the `mbbs` CSV. The `mbbs` and `mcs` arrays are then concatenated as a `ConcatLblDataset` object (which is defined for this purpose). This is done by concatenating the actual `mcs` array with the dataset of the ModelData object - which is where the `mbbs` array used to initalize the ModelData object lives.\n",
    "\n",
    "The basic idea is:\n",
    "\n",
    "- There are two arrays of output data for the dataset: classes per image (`mcs`) and bounding-boxes per image (`mbbs`).\n",
    "- A ModelData object is created using one of the data arrays.\n",
    "- The other data array is then concatenated with a copy of the first array *from* the ModelData object.\n",
    "- The ModelData object's dataset is updated to be the new concatenation.\n",
    "\n",
    "Also note the necessary transforms, and pointed the ModelData constructor to the correct CSV and data folders, *and* specifying `continous=True` to run regression on location (bounding box coordinates) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup (spec paths & put csv where it's expected)\n",
    "os.makedirs(PATH/'tmp', exist_ok=True)\n",
    "\n",
    "jpeg_path = PATH_TRAIN\n",
    "MBB_CSV = PATH/'tmp/mbb.csv'\n",
    "\n",
    "df_mbb.to_csv(MBB_CSV, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms=tfms_from_model(resnet34, sz=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ImageClassifierData.from_csv(path, jpeg_path, MBB_CSV, tfms=tfms, continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatLblDataset(Dataset):\n",
    "    def __init__(self, ds, y2):\n",
    "        self.ds,self.y2 = ds,y2\n",
    "        self.sz = ds.sz\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "    def __getitem__(self, i):\n",
    "        x,y = self.ds[i]\n",
    "        return (x, (y, self.y2[i]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds2 = ConcatLblDataset(md.trn_ds, mcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.trn_dl.dataset = trn_ds2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then you go from there.\n",
    "\n",
    "***NOTE***: probably have to specify a validation set during this process. Same steps for the concatenated validation dataset:\n",
    "\n",
    "```\n",
    "val_ds2 = ConcatLblDataset(md.val_ds, val_mcs)\n",
    "md.val_dl.dataset = val_ds2\n",
    "```\n",
    "\n",
    "The only functional thing left to do is to define the Neural Net's architecture and loss function. The architecture must have two output heads for boundingbox regression and classification (these require different loss functions). The architecure will also define the granularity of anchors boxes for detection. The loss function will optimize for classification and detection (**NOTE**: *I still have to see exactly how this works*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## temp - Single-Shot Detector Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StdConv(nn.Module):\n",
    "    def __init__(self, nin, nout, stride=2, drop=0.1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(nin, nout, 3, stride=stride, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(nout)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "        \n",
    "    def forward(self, x): return self.drop(self.bn(F.relu(self.conv(x))))\n",
    "    \n",
    "def flatten_conv(x,k):\n",
    "    bs,nf,gx,gy = x.size()\n",
    "    x = x.permute(0,2,3,1).contiguous()\n",
    "    return x.view(bs, -1, nf // k)\n",
    "\n",
    "class OutConv(nn.Module): # 2 separate output conv layers: bbx reg & clsfn\n",
    "    def __init__(self, k, nin, bias):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.oconv1 = nn.Conv2d(nin, (len(id2cat) + 1)*k, 3, padding=1)\n",
    "        self.oconv2 = nn.Conv2d(nin, 4*k, 3, padding=1)\n",
    "        self.oconv1.bias.data.zero_().add_(bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return [flatten_conv(self.oconv1(x), self.k), \n",
    "                flatten_conv(self.oconv2(x), self.k)]\n",
    "In [54]:\n",
    "class SSD_Head(nn.Module):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSD_Head(nn.Module):\n",
    "    def __init__(self, k, bias):\n",
    "        super().__init__()\n",
    "        self.drop = nn.Dropout(0.25)\n",
    "        self.sconv0 = StdConv(512, 256, stride=1) # stride 1 doesnt change geometry while adding a computation layer\n",
    "#         self.sconv1 = StdConv(256, 256)\n",
    "        self.sconv2 = StdConv(256, 256)\n",
    "        self.out = OutConv(k, 256, bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.drop(F.relu(x))\n",
    "        x = self.sconv0(x)\n",
    "#         x = self.sconv1(x)\n",
    "        x = self.sconv2(x)\n",
    "        return self.out(x)\n",
    "    \n",
    "head_reg4 = SSD_Head(k, -3.)\n",
    "models = ConvnetBuilder(f_model, 0, 0, 0, custom_head=head_reg4)\n",
    "learn  = ConvLearner(md, models)\n",
    "learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSD_MultiHead(nn.Module):\n",
    "    def __init__(self, k, bias):\n",
    "        super().__init__()\n",
    "        self.drop = nn.Dropout(drop)\n",
    "        self.sconv1 = StdConv(512, 256, drop=drop) # stride 2 conv halves grid size\n",
    "        self.sconv2 = StdConv(256, 256, drop=drop)\n",
    "        self.sconv3 = StdConv(256, 256, drop=drop)\n",
    "#         self.out0 = OutConv(k, 256, bias) # dont think this is used\n",
    "        self.out1 = OutConv(k, 256, bias)\n",
    "        self.out2 = OutConv(k, 256, bias)\n",
    "        self.out3 = OutConv(k, 256, bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.drop(F.relu(x))\n",
    "        x = self.sconv1(x) # 4x4 anchor size\n",
    "        o1c,o1λ = self.out1(x) # grab outputs (anchors)\n",
    "        x = self.sconv2(x) # 2x2\n",
    "        o2c,o2λ = self.out2(x)\n",
    "        x = self.sconv3(x) # 1x1\n",
    "        o3c,o3λ = self.out3(x)\n",
    "#         return [o1c,o1λ]\n",
    "        return [torch.cat([o1c,o2c,o3c], dim=1),\n",
    "                torch.cat([o1λ,o2λ,o3λ], dim=1)]\n",
    "\n",
    "head_reg4 = SSD_MultiHead(k, -4)\n",
    "models = ConvnetBuilder(f_model, 0, 0, 0, custom_head=head_reg4)\n",
    "learn = ConvLearner(md, models)\n",
    "learn.opt_fn = optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (FastAI)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
